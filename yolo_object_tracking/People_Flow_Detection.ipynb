{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOn22CWiydlq",
        "outputId": "b4df455d-fd83-4f1f-ab7f-ba559b82dac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install ultralytics deep_sort_realtime opencv-python-headless matplotlib numpy --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v62VoKW2y3Zn",
        "outputId": "c67ec062-343c-4ac0-c711-96cd43b25b4c"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow \n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    VIDEO_PATH = filename\n",
        "print(f\"Uploaded video file: {VIDEO_PATH}\")\n",
        "\n",
        "#title Configuration (Change lines here as needed)\n",
        "LINE_UP = 150       # Y-coordinate of upper horizontal line\n",
        "LINE_DOWN = 400     # Y-coordinate of lower horizontal line\n",
        "CONF_THRESH = 0.4   # Detection confidence threshold\n",
        "\n",
        "OUTPUT_VIDEO_PATH = \"output_people_count_heatmap.mp4\"\n",
        "HEATMAP_PATH = \"heatmap.png\"\n",
        "\n",
        "COLOR_LINE_UP = (0, 255, 0)\n",
        "COLOR_LINE_DOWN = (0, 0, 255)\n",
        "COLOR_IN = (0, 255, 0)\n",
        "COLOR_OUT = (0, 0, 255)\n",
        "\n",
        "PERSON_CLASS = 0\n",
        "\n",
        "#@title Initialize models and variables\n",
        "model = YOLO(\"yolov8n.pt\") \n",
        "tracker = DeepSort(max_age=30, n_init=3, nms_max_overlap=1.0, max_cosine_distance=0.2)\n",
        "\n",
        "track_memory = {}  # track_id: last_center_y\n",
        "count_in = 0\n",
        "count_out = 0\n",
        "heatmap_accum = None\n",
        "\n",
        "# Helper functions\n",
        "\n",
        "def draw_lines(frame):\n",
        "    h, w = frame.shape[:2]\n",
        "    cv2.line(frame, (0, LINE_UP), (w, LINE_UP), COLOR_LINE_UP, 2)\n",
        "    cv2.line(frame, (0, LINE_DOWN), (w, LINE_DOWN), COLOR_LINE_DOWN, 2)\n",
        "\n",
        "def update_counts(track_id, y, track_memory):\n",
        "    global count_in, count_out\n",
        "    if track_id in track_memory:\n",
        "        prev_y = track_memory[track_id]\n",
        "        if prev_y < LINE_UP and y >= LINE_UP:\n",
        "            count_in += 1\n",
        "            del track_memory[track_id]\n",
        "            return \"IN\"\n",
        "        elif prev_y > LINE_DOWN and y <= LINE_DOWN:\n",
        "            count_out += 1\n",
        "            del track_memory[track_id]\n",
        "            return \"OUT\"\n",
        "    track_memory[track_id] = y\n",
        "    return None\n",
        "\n",
        "def generate_heatmap(heatmap_accum, centers, frame_shape):\n",
        "    for c in centers:\n",
        "        x, y = int(c[0]), int(c[1])\n",
        "        if 0 <= y < frame_shape[0] and 0 <= x < frame_shape[1]:\n",
        "            heatmap_accum[y, x] += 1\n",
        "    return heatmap_accum\n",
        "\n",
        "#Run detection, tracking, counting, heatmap\n",
        "def main():\n",
        "    global heatmap_accum, count_in, count_out\n",
        "\n",
        "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Cannot open video: {VIDEO_PATH}\")\n",
        "        return\n",
        "\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    heatmap_accum = np.zeros((height, width), dtype=np.float32)\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (width, height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = model.predict(frame, conf=CONF_THRESH, classes=[PERSON_CLASS], verbose=False)\n",
        "\n",
        "        detections = []\n",
        "        centers = []\n",
        "\n",
        "        for r in results:\n",
        "            boxes = r.boxes\n",
        "            for box in boxes:\n",
        "                xyxy = box.xyxy[0].cpu().numpy()\n",
        "                conf = box.conf[0].cpu().numpy()\n",
        "                cls = int(box.cls[0].cpu().numpy())\n",
        "\n",
        "                if conf < CONF_THRESH or cls != PERSON_CLASS:\n",
        "                    continue\n",
        "\n",
        "                x1, y1, x2, y2 = map(int, xyxy)\n",
        "                w = x2 - x1\n",
        "                h = y2 - y1\n",
        "                cx = int((x1 + x2) / 2)\n",
        "                cy = int((y1 + y2) / 2)\n",
        "                centers.append((cx, cy))\n",
        "                # Pass detections as a tuple: ((x1, y1, w, h), conf)\n",
        "                detections.append(((x1, y1, w, h), conf))\n",
        "\n",
        "\n",
        "        heatmap_accum = generate_heatmap(heatmap_accum, centers, (height, width))\n",
        "\n",
        "        tracks = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "        draw_lines(frame)\n",
        "\n",
        "        for track in tracks:\n",
        "            # Check if the track is confirmed before processing\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "            track_id = track.track_id\n",
        "            ltrb = track.to_ltrb()\n",
        "            x1, y1, x2, y2 = map(int, ltrb)\n",
        "            cx = int((x1 + x2) / 2)\n",
        "            cy = int((y1 + y2) / 2)\n",
        "\n",
        "            result = update_counts(track_id, cy, track_memory)\n",
        "\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"ID:{track_id}\", (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
        "\n",
        "            if result == \"IN\":\n",
        "                cv2.putText(frame, \"IN\", (cx, cy),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 1, COLOR_IN, 3)\n",
        "            elif result == \"OUT\":\n",
        "                cv2.putText(frame, \"OUT\", (cx, cy),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 1, COLOR_OUT, 3)\n",
        "\n",
        "        cv2.putText(frame, f\"IN: {count_in}\", (10, 30),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, COLOR_IN, 2)\n",
        "        cv2.putText(frame, f\"OUT: {count_out}\", (10, 70),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, COLOR_OUT, 2)\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "        # Show live frame (optional, comment if slow)\n",
        "        cv2_imshow(frame) # Use cv2_imshow instead of cv2.imshow\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # Save heatmap image\n",
        "    heatmap_norm = cv2.normalize(heatmap_accum, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "    heatmap_color = cv2.applyColorMap(heatmap_norm, cv2.COLORMAP_JET)\n",
        "    cv2.imwrite(HEATMAP_PATH, heatmap_color)\n",
        "\n",
        "    # Display heatmap\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(\"Heatmap of Movement Intensity\")\n",
        "    plt.imshow(cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Finished! Output video saved as {OUTPUT_VIDEO_PATH}\")\n",
        "    print(f\"Heatmap saved as {HEATMAP_PATH}\")\n",
        "\n",
        "#@title Run main\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
